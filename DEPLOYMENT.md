# AI Writer é¡¹ç›®éƒ¨ç½²æŒ‡å— - WSL2 Ubuntu

**é€‚ç”¨äºç¬”è®°æœ¬ç”µè„‘çš„å®Œæ•´éƒ¨ç½²æŒ‡å— - åŒ…å«æœ¬åœ° LLM é…ç½®**

---

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹) - 5åˆ†é’Ÿå¿«é€Ÿéƒ¨ç½²
2. [å®Œæ•´éƒ¨ç½²æ­¥éª¤](#å®Œæ•´éƒ¨ç½²æ­¥éª¤) - è¯¦ç»†å®‰è£…æŒ‡å—
3. [Ollama æœ¬åœ° LLM é…ç½®](#ollama-æœ¬åœ°-llm-é…ç½®) - å¯é€‰åŠŸèƒ½
4. [WSL2 ä¸“ç”¨é…ç½®](#wsl2-ä¸“ç”¨é…ç½®)
5. [ç¬”è®°æœ¬æ€§èƒ½ä¼˜åŒ–](#ç¬”è®°æœ¬æ€§èƒ½ä¼˜åŒ–)
6. [åŠŸèƒ½è¯´æ˜](#åŠŸèƒ½è¯´æ˜)
7. [å¸¸è§é—®é¢˜è§£å†³](#å¸¸è§é—®é¢˜è§£å†³)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

**é€‚åˆå·²å®‰è£… WSL2 Ubuntu çš„ç”¨æˆ·**

### åŸºç¡€æ¨¡å¼ï¼ˆæ¨èæ–°æ‰‹ï¼‰

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/fsxbmb/Ai-Writer.git
cd Ai-Writer

# 2. å®‰è£…åç«¯ä¾èµ–
cd backend
pip install -r requirements.txt
cp .env.example .env

# 3. å®‰è£…å‰ç«¯ä¾èµ–
cd ../frontend
npm install

# 4. å¯åŠ¨æœåŠ¡
# ç»ˆç«¯1: cd backend && python -m app.main
# ç»ˆç«¯2: cd frontend && npm run dev

# 5. è®¿é—®åº”ç”¨
# æµè§ˆå™¨æ‰“å¼€: http://localhost:5173
```

### å®Œæ•´æ¨¡å¼ï¼ˆå« Ollama å’Œ Milvusï¼‰

```bash
# é¢å¤–æ­¥éª¤ï¼šå®‰è£… Ollamaï¼ˆç”¨äºæœ¬åœ° LLMï¼‰
curl -fsSL https://ollama.com/install.sh | sh

# å¯åŠ¨ Ollama æœåŠ¡
ollama serve &

# ä¸‹è½½æ¨¡å‹ï¼ˆç¤ºä¾‹ï¼šQwen2.5ï¼‰
ollama pull qwen2.5:7b

# å¯åŠ¨ Milvusï¼ˆç”¨äºå‘é‡æœç´¢ï¼‰
cd milvus && docker compose up -d
```

---

## ğŸ“¦ å®Œæ•´éƒ¨ç½²æ­¥éª¤

### ç¬¬ä¸€æ­¥ï¼šåœ¨ Windows ä¸Šå®‰è£… WSL2

#### 1.1 æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
- Windows 10 ç‰ˆæœ¬ 2004 æˆ–æ›´é«˜ï¼ˆå†…éƒ¨ç‰ˆæœ¬ 19041 æˆ–æ›´é«˜ï¼‰
- æˆ– Windows 11
- è‡³å°‘ 8GB RAMï¼ˆæ¨è 16GBï¼Œä½¿ç”¨æœ¬åœ° LLM å»ºè®® 32GBï¼‰
- è‡³å°‘ 20GB å¯ç”¨ç£ç›˜ç©ºé—´

#### 1.2 å®‰è£… WSL2
```powershell
# åœ¨ PowerShell (ç®¡ç†å‘˜) ä¸­è¿è¡Œ
wsl --install

# é‡å¯è®¡ç®—æœºåï¼ŒWSL ä¼šè‡ªåŠ¨å®‰è£… Ubuntu
# è®¾ç½®ç”¨æˆ·åå’Œå¯†ç 
```

#### 1.3 æ›´æ–° WSL2ï¼ˆå¯é€‰ä½†æ¨èï¼‰
```powershell
wsl --update
```

---

### ç¬¬äºŒæ­¥ï¼šé…ç½® WSL2 Ubuntu

#### 2.1 æ›´æ–°ç³»ç»Ÿ
```bash
# è¿›å…¥ WSL2 Ubuntu
sudo apt update && sudo apt upgrade -y
```

#### 2.2 å®‰è£…åŸºç¡€å·¥å…·
```bash
# å®‰è£…å¿…è¦å·¥å…·
sudo apt install -y curl git wget build-essential vim

# å®‰è£… Python 3 å’Œ pip
sudo apt install -y python3 python3-pip python3-venv

# å®‰è£… Node.js 18+
curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -
sudo apt install -y nodejs

# éªŒè¯å®‰è£…
echo "Node.js: $(node --version)"
echo "npm: $(npm --version)"
echo "Python: $(python3 --version)"
```

#### 2.3 å®‰è£…æ–‡æ¡£è½¬æ¢ä¾èµ–ï¼ˆå¯é€‰ï¼‰

å¦‚æœéœ€è¦ä½¿ç”¨æ–‡æ¡£å¯¼å‡ºåŠŸèƒ½ï¼š

```bash
# å®‰è£… wkhtmltopdfï¼ˆç”¨äº HTML è½¬ PDFï¼‰
sudo apt install -y wkhtmltopdf

# å®‰è£… Pandocï¼ˆç”¨äºæ–‡æ¡£æ ¼å¼è½¬æ¢ï¼‰
sudo apt install -y pandoc
```

#### 2.4 é…ç½® Gitï¼ˆå¯é€‰ï¼‰
```bash
git config --global user.name "Your Name"
git config --global user.email "your.email@example.com"
```

---

### ç¬¬ä¸‰æ­¥ï¼šå®‰è£… Dockerï¼ˆå¯é€‰ï¼Œç”¨äº Milvusï¼‰

**âš ï¸ æ³¨æ„ï¼šDocker ä¼šå ç”¨è¾ƒå¤šèµ„æºï¼Œå¦‚æœä¸éœ€è¦å‘é‡æœç´¢åŠŸèƒ½å¯ä»¥è·³è¿‡**

```bash
# å®‰è£… Docker
curl -fsSL https://get.docker.com | sudo sh

# å°†å½“å‰ç”¨æˆ·æ·»åŠ åˆ° docker ç»„
sudo usermod -aG docker $USER

# é‡æ–°ç™»å½• WSL ä½¿é…ç½®ç”Ÿæ•ˆ
# åœ¨ PowerShell ä¸­è¿è¡Œ: wsl --shutdown
# ç„¶åé‡æ–°æ‰“å¼€ WSL

# éªŒè¯å®‰è£…
docker --version
```

---

### ç¬¬å››æ­¥ï¼šå®‰è£… Ollamaï¼ˆå¯é€‰ï¼Œç”¨äºæœ¬åœ° LLMï¼‰

**âš ï¸ æ³¨æ„ï¼šOllama éœ€è¦ GPU æ”¯æŒï¼ˆæ¨èï¼‰æˆ–å……è¶³çš„ CPU èµ„æº**

#### 4.1 å®‰è£… Ollama

```bash
# å®˜æ–¹å®‰è£…è„šæœ¬
curl -fsSL https://ollama.com/install.sh | sh

# éªŒè¯å®‰è£…
ollama --version
```

#### 4.2 ä¸‹è½½æ¨¡å‹

```bash
# å¯åŠ¨ Ollama æœåŠ¡
ollama serve &

# ç­‰å¾…æœåŠ¡å¯åŠ¨åï¼Œä¸‹è½½æ¨¡å‹
# å°æ¨¡å‹ï¼ˆé€‚åˆ 8-16GB RAMï¼‰
ollama pull qwen2.5:3b

# ä¸­ç­‰æ¨¡å‹ï¼ˆæ¨èï¼Œé€‚åˆ 16-32GB RAMï¼‰
ollama pull qwen2.5:7b
ollama pull qwen2.5:14b

# å¤§æ¨¡å‹ï¼ˆé€‚åˆ 32GB+ RAMï¼‰
ollama pull qwen2.5:32b

# æŸ¥çœ‹å·²å®‰è£…çš„æ¨¡å‹
ollama list
```

#### 4.3 æµ‹è¯• Ollama

```bash
# æµ‹è¯•å¯¹è¯
ollama run qwen2.5:7b "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
ollama show qwen2.5:7b
```

---

### ç¬¬äº”æ­¥ï¼šå…‹éš†é¡¹ç›®

```bash
# é€‰æ‹©é¡¹ç›®å®‰è£…ä½ç½®ï¼ˆæ¨èæ”¾åœ¨ç”¨æˆ·ç›®å½•ä¸‹ï¼‰
cd ~

# å…‹éš†é¡¹ç›®
git clone https://github.com/fsxbmb/Ai-Writer.git
cd Ai-Writer

# æŸ¥çœ‹é¡¹ç›®ç»“æ„
ls -la
```

---

### ç¬¬å…­æ­¥ï¼šå®‰è£…é¡¹ç›®ä¾èµ–

#### 6.1 åç«¯å®‰è£…

```bash
# è¿›å…¥åç«¯ç›®å½•
cd backend

# åˆ›å»º Python è™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3 -m venv venv
source venv/bin/activate

# å‡çº§ pip
pip install --upgrade pip

# å®‰è£…ä¾èµ–ï¼ˆä½¿ç”¨å›½å†…é•œåƒåŠ é€Ÿï¼‰
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# å®‰è£… MinerUï¼ˆå¯é€‰ï¼Œç”¨äº PDF è§£æï¼‰
pip install mineru

# å®‰è£…é¢å¤–çš„å‘é‡æœç´¢ä¾èµ–ï¼ˆå¦‚æœä½¿ç”¨ Milvusï¼‰
pip install pymilvus sentence-transformers

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env

# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p uploads parsed_output parsed_data images
```

#### 6.2 é…ç½®åç«¯ç¯å¢ƒå˜é‡

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼š

```bash
nano .env
```

æ·»åŠ  Ollama é…ç½®ï¼ˆå¦‚æœå·²å®‰è£…ï¼‰ï¼š

```env
# FastAPI é…ç½®
APP_NAME=AI Writer Backend
APP_VERSION=0.0.1
DEBUG=True
HOST=0.0.0.0
PORT=8000

# CORS é…ç½®
CORS_ORIGINS=["http://localhost:5173","http://127.0.0.1:5173"]

# æ–‡ä»¶å­˜å‚¨é…ç½®
UPLOAD_DIR=./uploads
PARSE_OUTPUT_DIR=./parsed_data
MAX_UPLOAD_SIZE=104857600  # 100MB

# MinerU é…ç½®
MINERU_BACKEND=pipeline
MINERU_OUTPUT_DIR=./parsed_output
MINERU_LANG=ch

# Ollama é…ç½®ï¼ˆå¦‚æœä½¿ç”¨æœ¬åœ° LLMï¼‰
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
OLLAMA_TIMEOUT=120

# Milvus é…ç½®ï¼ˆå¦‚æœä½¿ç”¨å‘é‡æœç´¢ï¼‰
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

#### 6.3 å‰ç«¯å®‰è£…

```bash
# è¿›å…¥å‰ç«¯ç›®å½•
cd ../frontend

# é…ç½® npm ä½¿ç”¨å›½å†…é•œåƒ
npm config set registry https://registry.npmmirror.com

# å®‰è£…ä¾èµ–
npm install

# éªŒè¯å®‰è£…
npm run build  # æµ‹è¯•ç¼–è¯‘æ˜¯å¦æˆåŠŸ
rm -rf dist     # åˆ é™¤æµ‹è¯•æ„å»º
```

---

### ç¬¬ä¸ƒæ­¥ï¼šå¯åŠ¨åº”ç”¨

#### æ–¹å¼ Aï¼šåŸºç¡€æ¨¡å¼ï¼ˆæ¨èæ–°æ‰‹ï¼‰

**ä»…å¯åŠ¨å‰åç«¯ï¼Œä½¿ç”¨æ¨¡æ‹Ÿ LLM**

```bash
# ç»ˆç«¯ 1 - å¯åŠ¨åç«¯
cd ~/Ai-Writer/backend
source venv/bin/activate  # å¦‚æœä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ
python -m app.main

# ç»ˆç«¯ 2 - å¯åŠ¨å‰ç«¯
cd ~/Ai-Writer/frontend
npm run dev
```

**è®¿é—®åœ°å€**ï¼š
- å‰ç«¯ï¼šhttp://localhost:5173
- åç«¯ APIï¼šhttp://localhost:8000
- API æ–‡æ¡£ï¼šhttp://localhost:8000/docs

#### æ–¹å¼ Bï¼šæœ¬åœ° LLM æ¨¡å¼

**ä½¿ç”¨ Ollama æœ¬åœ°æ¨¡å‹**

```bash
# ç»ˆç«¯ 1 - å¯åŠ¨ Ollama
ollama serve

# ç»ˆç«¯ 2 - å¯åŠ¨åç«¯
cd ~/Ai-Writer/backend
source venv/bin/activate
python -m app.main

# ç»ˆç«¯ 3 - å¯åŠ¨å‰ç«¯
cd ~/Ai-Writer/frontend
npm run dev
```

**ç‰¹ç‚¹**ï¼š
- âœ… å®Œå…¨ç¦»çº¿è¿è¡Œ
- âœ… æ•°æ®éšç§ä¿æŠ¤
- âœ… æ— éœ€ API è´¹ç”¨
- âš ï¸ éœ€è¦è¾ƒå¥½çš„ç¡¬ä»¶é…ç½®

#### æ–¹å¼ Cï¼šå®Œæ•´æ¨¡å¼ï¼ˆå«å‘é‡æœç´¢ï¼‰

**åŒ…å« Milvus å‘é‡æ•°æ®åº“ï¼Œæ”¯æŒé«˜çº§ RAG åŠŸèƒ½**

```bash
# ç»ˆç«¯ 1 - å¯åŠ¨ Milvus
cd ~/Ai-Writer/milvus
docker compose up -d

# ç­‰å¾… 30-60 ç§’ï¼Œæ£€æŸ¥çŠ¶æ€
docker compose ps

# ç»ˆç«¯ 2 - å¯åŠ¨ Ollamaï¼ˆå¯é€‰ï¼‰
ollama serve

# ç»ˆç«¯ 3 - å¯åŠ¨åç«¯
cd ~/Ai-Writer/backend
source venv/bin/activate
python -m app.main

# ç»ˆç«¯ 4 - å¯åŠ¨å‰ç«¯
cd ~/Ai-Writer/frontend
npm run dev
```

---

## ğŸ¤– Ollama æœ¬åœ° LLM é…ç½®

### æ¨èæ¨¡å‹

æ ¹æ®ç¡¬ä»¶é…ç½®é€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼š

| RAM é…ç½® | æ¨èæ¨¡å‹ | å‘½ä»¤ | è¯´æ˜ |
|---------|---------|------|------|
| 8GB | qwen2.5:3b | `ollama pull qwen2.5:3b` | è½»é‡çº§ï¼Œé€Ÿåº¦æœ€å¿« |
| 16GB | qwen2.5:7b | `ollama pull qwen2.5:7b` | å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦ |
| 32GB | qwen2.5:14b | `ollama pull qwen2.5:14b` | æ›´å¥½çš„æ¨ç†èƒ½åŠ› |
| 64GB+ | qwen2.5:32b | `ollama pull qwen2.5:32b` | æœ€ä½³æ€§èƒ½ |

### æ¨¡å‹ç®¡ç†

```bash
# æŸ¥çœ‹å·²å®‰è£…æ¨¡å‹
ollama list

# åˆ é™¤æ¨¡å‹
ollama rm qwen2.5:3b

# æ›´æ–°æ¨¡å‹
ollama pull qwen2.5:7b

# æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯
ollama show qwen2.5:7b

# è¿è¡Œæ¨¡å‹æµ‹è¯•
ollama run qwen2.5:7b
```

### æ€§èƒ½ä¼˜åŒ–

**GPU åŠ é€Ÿï¼ˆå¦‚æœæœ‰ NVIDIA æ˜¾å¡ï¼‰**ï¼š

```bash
# å®‰è£… NVIDIA CUDA å·¥å…·åŒ…
sudo apt install -y nvidia-cuda-toolkit

# éªŒè¯ GPU è¯†åˆ«
nvidia-smi

# Ollama ä¼šè‡ªåŠ¨ä½¿ç”¨ GPU
```

**CPU æ¨¡å¼ä¼˜åŒ–**ï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡é™åˆ¶ CPU ä½¿ç”¨
export OLLAMA_NUM_GPU=0
export OLLAMA_NUM_THREAD=4
```

---

## ğŸ”§ WSL2 ä¸“ç”¨é…ç½®

### ç½‘ç»œè®¿é—®é…ç½®

WSL2 ä½¿ç”¨è™šæ‹Ÿç½‘ç»œï¼Œåœ¨ Windows æµè§ˆå™¨è®¿é—®æ—¶ï¼š

```bash
# æ–¹å¼ 1: ä½¿ç”¨ localhostï¼ˆæ¨èï¼‰
# WSL2 ä¼šè‡ªåŠ¨è½¬å‘ localhost ç«¯å£
# http://localhost:5173

# æ–¹å¼ 2: ä½¿ç”¨ WSL2 IP åœ°å€
hostname -I  # è·å– WSL2 IP
# http://172.x.x.x:5173
```

### æ–‡ä»¶è®¿é—®

**Windows è®¿é—® WSL2 æ–‡ä»¶**ï¼š
```powershell
# åœ¨æ–‡ä»¶èµ„æºç®¡ç†å™¨ä¸­
\\wsl$\Ubuntu\home\ä½ çš„ç”¨æˆ·å\Ai-Writer
```

**WSL2 è®¿é—® Windows æ–‡ä»¶**ï¼š
```bash
cd /mnt/c/Users/ä½ çš„ç”¨æˆ·å/
```

### æ€§èƒ½ä¼˜åŒ–

**å°†é¡¹ç›®æ”¾åœ¨ WSL2 æ–‡ä»¶ç³»ç»Ÿä¸­**ï¼š
```bash
# âœ… æ¨èï¼šæ”¾åœ¨ WSL2 æ–‡ä»¶ç³»ç»Ÿ
cd ~
git clone https://github.com/fsxbmb/Ai-Writer.git

# âŒ ä¸æ¨èï¼šæ”¾åœ¨ /mnt/cï¼ˆæ€§èƒ½å·®ï¼‰
cd /mnt/c/Users/
git clone https://github.com/fsxbmb/Ai-Writer.git
```

---

## ğŸ’» ç¬”è®°æœ¬ç”µè„‘æ€§èƒ½ä¼˜åŒ–

### 1. å†…å­˜ä¼˜åŒ–

**æ£€æŸ¥å†…å­˜ä½¿ç”¨**ï¼š
```bash
free -h
```

**é™åˆ¶ Docker å†…å­˜å ç”¨**ï¼š
```bash
# ç¼–è¾‘ Docker é…ç½®
sudo vim /etc/docker/daemon.json

# æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼ˆæ ¹æ®ç¬”è®°æœ¬å†…å­˜è°ƒæ•´ï¼‰
{
  "memory": "4g",
  "memory-swap": "4g"
}

# é‡å¯ Docker
sudo systemctl restart docker
```

### 2. CPU ä¼˜åŒ–

**æ£€æŸ¥ CPU æ ¸å¿ƒæ•°**ï¼š
```bash
nproc
```

**é™åˆ¶åç«¯ worker æ•°é‡**ï¼š
```bash
# ç¼–è¾‘ backend å¯åŠ¨å‘½ä»¤
uvicorn app.main:app --workers 2  # æ ¹æ®æ ¸å¿ƒæ•°è°ƒæ•´
```

### 3. Ollama æ€§èƒ½è°ƒæ•´

**æ ¹æ®ç¡¬ä»¶é€‰æ‹©åˆé€‚çš„æ¨¡å‹**ï¼š

```bash
# 8GB RAM - ä½¿ç”¨å°æ¨¡å‹
ollama pull qwen2.5:3b

# 16GB RAM - ä½¿ç”¨ä¸­ç­‰æ¨¡å‹
ollama pull qwen2.5:7b

# ç¦ç”¨ GPUï¼ˆå¦‚æœæ²¡æœ‰ç‹¬ç«‹æ˜¾å¡ï¼‰
export OLLAMA_NUM_GPU=0
```

### 4. ç£ç›˜ä¼˜åŒ–

**å°†ä¾èµ–å®‰è£…åœ¨è™šæ‹Ÿç¯å¢ƒä¸­**ï¼ŒèŠ‚çœç³»ç»Ÿç©ºé—´ï¼š
```bash
# ä½¿ç”¨ Python è™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 5. ç”µæºç®¡ç†

**ç¬”è®°æœ¬ä½¿ç”¨æ—¶å»ºè®®**ï¼š
- âœ… æ¥é€šç”µæºè¿è¡Œå¼€å‘ç¯å¢ƒ
- âœ… ä½¿ç”¨"é«˜æ€§èƒ½"ç”µæºæ¨¡å¼
- âš ï¸ ç”µæ± æ¨¡å¼ä¸‹å¯èƒ½æ€§èƒ½ä¸‹é™
- âš ï¸ ä½¿ç”¨ Ollama æ—¶åŠ¡å¿…æ¥é€šç”µæº

---

## ğŸ“– åŠŸèƒ½è¯´æ˜

### 1. çŸ¥è¯†åº“ç®¡ç†

**åŸºç¡€åŠŸèƒ½**ï¼š
- PDF æ–‡æ¡£ä¸Šä¼ å’Œç®¡ç†
- MinerU æ™ºèƒ½è§£æï¼ˆéœ€è¦å®‰è£…ï¼‰
- Markdown ç¼–è¾‘å’Œé¢„è§ˆ
- æ ‡ç­¾åˆ†ç±»å’Œæœç´¢

**æ— éœ€é¢å¤–é…ç½®**ï¼Œå¯åŠ¨å³å¯ä½¿ç”¨ã€‚

### 2. çŸ¥è¯†é—®ç­” (RAG)

**ä¸¤ç§æ¨¡å¼**ï¼š

**A. æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆæ— éœ€é¢å¤–é…ç½®ï¼‰**
- ä½¿ç”¨ç®€å•çš„åŒ¹é…ç®—æ³•
- å¿«é€Ÿå“åº”
- é€‚åˆæµ‹è¯•å’Œæ¼”ç¤º

**B. é«˜çº§æ¨¡å¼ï¼ˆéœ€è¦ Milvus + Ollamaï¼‰**
- å‘é‡è¯­ä¹‰æœç´¢
- LLM æ™ºèƒ½å›ç­”
- éœ€è¦æ›´å¤šèµ„æº
- æ›´å¥½çš„é—®ç­”è´¨é‡

### 3. æ–‡æ¡£ç”Ÿæˆ

**æ”¯æŒçš„æ¨¡å¼**ï¼š

**A. æ¨¡æ¿ç”Ÿæˆï¼ˆæ— éœ€ LLMï¼‰**
- ä½¿ç”¨é¢„è®¾æ¨¡æ¿
- å¿«é€Ÿç”ŸæˆåŸºç¡€æ–‡æ¡£

**B. AI è¾…åŠ©ç”Ÿæˆï¼ˆéœ€è¦ Ollamaï¼‰**
- LLM æ™ºèƒ½ç”Ÿæˆ
- æ ¹æ®ä¸Šä¸‹æ–‡å†™ä½œ
- æ”¯æŒå¤šç§é£æ ¼

### 4. æ–‡æ¡£å¯¼å‡º

**æ”¯æŒçš„æ ¼å¼**ï¼š
- Markdown (.md)
- PDF (.pdf) - éœ€è¦ wkhtmltopdf
- çº¯æ–‡æœ¬ (.txt)
- HTML (.html)

---

## ğŸ” å¸¸è§é—®é¢˜è§£å†³

### é—®é¢˜ 1ï¼šnpm install å¤±è´¥

**é”™è¯¯**ï¼š`ECONNREFUSED` æˆ–ç½‘ç»œè¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨å›½å†…é•œåƒ
npm config set registry https://registry.npmmirror.com
npm config set disturl https://npmmirror.com/mirrors/node/

# é‡æ–°å®‰è£…
rm -rf node_modules package-lock.json
npm install
```

### é—®é¢˜ 2ï¼šPython ä¾èµ–å®‰è£…å¤±è´¥

**é”™è¯¯**ï¼š`pip install` é€Ÿåº¦æ…¢æˆ–å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å‡çº§ pip
pip install --upgrade pip

# ä½¿ç”¨æ¸…åé•œåƒ
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

# æˆ–è€…æ°¸ä¹…é…ç½®
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple
```

### é—®é¢˜ 3ï¼šç«¯å£è¢«å ç”¨

**é”™è¯¯**ï¼š`Address already in use`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æŸ¥çœ‹å ç”¨ç«¯å£çš„è¿›ç¨‹
sudo lsof -i :8000  # åç«¯
sudo lsof -i :5173  # å‰ç«¯
sudo lsof -i :11434 # Ollama

# æ€æ­»è¿›ç¨‹
sudo kill -9 <PID>

# æˆ–è€…ä¿®æ”¹ç«¯å£
# ç¼–è¾‘ backend/.env: PORT=8001
# ç¼–è¾‘ frontend/vite.config.ts: server.port: 5174
```

### é—®é¢˜ 4ï¼šDocker æƒé™é”™è¯¯

**é”™è¯¯**ï¼š`permission denied while trying to connect to the Docker daemon`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ·»åŠ ç”¨æˆ·åˆ° docker ç»„
sudo usermod -aG docker $USER

# é‡æ–°ç™»å½• WSL
# åœ¨ PowerShell è¿è¡Œï¼šwsl --shutdown
# ç„¶åé‡æ–°æ‰“å¼€ WSL
```

### é—®é¢˜ 5ï¼šMinerU æ— æ³•ä½¿ç”¨

**é”™è¯¯**ï¼šMinerU ç›¸å…³é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ–¹æ¡ˆ 1: å®‰è£… MinerU
pip install mineru

# æ–¹æ¡ˆ 2: è·³è¿‡ MinerUï¼Œé¡¹ç›®ä¼šä½¿ç”¨æ¨¡æ‹Ÿè§£æå™¨
# ä¸å½±å“å…¶ä»–åŠŸèƒ½ä½¿ç”¨
```

### é—®é¢˜ 6ï¼šWSL2 ç½‘ç»œæ— æ³•è®¿é—®

**é”™è¯¯**ï¼šWindows æµè§ˆå™¨æ— æ³•æ‰“å¼€ localhost:5173

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ WSL2 æœåŠ¡æ˜¯å¦è¿è¡Œ
cd ~/Ai-Writer/frontend
npm run dev

# åœ¨ Windows PowerShell ä¸­æ£€æŸ¥é˜²ç«å¢™
# æˆ–å°è¯•ä½¿ç”¨ WSL2 IP åœ°å€
hostname -I
# ä½¿ç”¨è¿”å›çš„ IP è®¿é—®ï¼Œå¦‚ï¼šhttp://172.30.144.1:5173
```

### é—®é¢˜ 7ï¼šç¬”è®°æœ¬æ€§èƒ½ä¸è¶³

**è¡¨ç°**ï¼šåº”ç”¨è¿è¡Œç¼“æ…¢ï¼Œå¡é¡¿

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# 1. å…³é—­ Milvusï¼ˆå¦‚æœä¸éœ€è¦å‘é‡æœç´¢ï¼‰
cd ~/Ai-Writer/milvus
docker compose down

# 2. ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull qwen2.5:3b

# 3. å‡å°‘ worker æ•°é‡
# ä¿®æ”¹åç«¯å¯åŠ¨ï¼Œä½¿ç”¨å•è¿›ç¨‹
python -m app.main

# 4. æ£€æŸ¥ç³»ç»Ÿèµ„æº
htop  # éœ€è¦å…ˆå®‰è£…: sudo apt install htop

# 5. æ¸…ç†ç³»ç»Ÿç¼“å­˜
sudo apt clean
sudo apt autoremove
```

### é—®é¢˜ 8ï¼šOllama æ— æ³•è¿æ¥

**é”™è¯¯**ï¼šåç«¯æ— æ³•è¿æ¥åˆ° Ollama

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€
ps aux | grep ollama

# å¯åŠ¨ Ollama æœåŠ¡
ollama serve &

# æµ‹è¯•è¿æ¥
curl http://localhost:11434/api/tags

# æ£€æŸ¥åç«¯é…ç½®
cat backend/.env | grep OLLAMA
```

### é—®é¢˜ 9ï¼šOllama æ¨¡å‹ä¸‹è½½å¤±è´¥

**é”™è¯¯**ï¼šæ¨¡å‹ä¸‹è½½ç¼“æ…¢æˆ–å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨ä»£ç†ï¼ˆå¦‚æœæœ‰ï¼‰
export HTTP_PROXY=http://your-proxy:port
export HTTPS_PROXY=http://your-proxy:port

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶
# å‚è€ƒï¼šhttps://ollama.com/download
```

### é—®é¢˜ 10ï¼šæ–‡æ¡£å¯¼å‡ºå¤±è´¥

**é”™è¯¯**ï¼šæ— æ³•å¯¼å‡º PDF æˆ– Word

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# å®‰è£…å¿…è¦çš„ç³»ç»Ÿä¾èµ–
sudo apt install -y wkhtmltopdf pandoc

# é‡æ–°å®‰è£… Python ä¾èµ–
pip install reportlab pdfkit
```

---

## ğŸ“ æ—¥å¸¸ä½¿ç”¨

### å¯åŠ¨åº”ç”¨ï¼ˆå®Œæ•´æ¨¡å¼ï¼‰

åˆ›å»ºå¯åŠ¨è„šæœ¬ `start-full.sh`ï¼š

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º
cat > start-full.sh << 'EOF'
#!/bin/bash

# å¯åŠ¨ Milvus
cd ~/Ai-Writer/milvus
docker compose up -d

# ç­‰å¾… Milvus å¯åŠ¨
sleep 30

# å¯åŠ¨ Ollama
ollama serve &
sleep 5

# å¯åŠ¨åç«¯
cd ~/Ai-Writer/backend
source venv/bin/activate
python -m app.main &

# å¯åŠ¨å‰ç«¯
cd ~/Ai-Writer/frontend
npm run dev &

echo "åº”ç”¨å·²å¯åŠ¨ï¼ˆå®Œæ•´æ¨¡å¼ï¼‰"
echo "å‰ç«¯: http://localhost:5173"
echo "åç«¯: http://localhost:8000"
echo "Milvus: http://localhost:9091"
EOF

chmod +x start-full.sh
./start-full.sh
```

### å¯åŠ¨åº”ç”¨ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰

åˆ›å»ºå¯åŠ¨è„šæœ¬ `start-basic.sh`ï¼š

```bash
cat > start-basic.sh << 'EOF'
#!/bin/bash

# å¯åŠ¨åç«¯
cd ~/Ai-Writer/backend
source venv/bin/activate
python -m app.main &

# å¯åŠ¨å‰ç«¯
cd ~/Ai-Writer/frontend
npm run dev &

echo "åº”ç”¨å·²å¯åŠ¨ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰"
echo "å‰ç«¯: http://localhost:5173"
echo "åç«¯: http://localhost:8000"
EOF

chmod +x start-basic.sh
./start-basic.sh
```

### åœæ­¢åº”ç”¨

```bash
# æŸ¥æ‰¾å¹¶åœæ­¢è¿›ç¨‹
pkill -f "python -m app.main"
pkill -f "npm run dev"

# åœæ­¢ Milvus
cd ~/Ai-Writer/milvus
docker compose down

# åœæ­¢ Ollama
pkill ollama
```

### æ›´æ–°é¡¹ç›®

```bash
cd ~/Ai-Writer
git pull origin main

# æ›´æ–°åç«¯
cd backend
source venv/bin/activate
pip install -r requirements.txt --upgrade

# æ›´æ–°å‰ç«¯
cd ../frontend
npm install

# é‡å¯æœåŠ¡
```

---

## ğŸ¯ å¼€å‘å»ºè®®

### 1. ä½¿ç”¨ VS Code è¿œç¨‹å¼€å‘

```bash
# åœ¨ WSL2 ä¸­å®‰è£… VS Code Server
code .

# æˆ–åœ¨ Windows VS Code ä¸­å®‰è£… "WSL" æ‰©å±•
# ç„¶ååœ¨ WSL ç»ˆç«¯è¿è¡Œ: code .
```

### 2. ä½¿ç”¨ PM2 ç®¡ç†è¿›ç¨‹

```bash
# å®‰è£… PM2
npm install -g pm2

# å¯åŠ¨åç«¯
cd ~/Ai-Writer/backend
pm2 start "python -m app.main" --name ai-writer-backend

# å¯åŠ¨å‰ç«¯
cd ~/Ai-Writer/frontend
pm2 start "npm run dev" --name ai-writer-frontend

# æŸ¥çœ‹çŠ¶æ€
pm2 status

# æŸ¥çœ‹æ—¥å¿—
pm2 logs

# åœæ­¢æ‰€æœ‰
pm2 stop all
```

### 3. æ•°æ®å¤‡ä»½

```bash
# å¤‡ä»½é‡è¦æ•°æ®
cp -r ~/Ai-Writer/backend/data ~/Ai-Writer-backup/
cp -r ~/Ai-Writer/backend/uploads ~/Ai-Writer-backup/
```

---

## ğŸ“š æŠ€æœ¯æ”¯æŒ

- **GitHub Issues**: https://github.com/fsxbmb/Ai-Writer/issues
- **API æ–‡æ¡£**: http://localhost:8000/docs
- **é¡¹ç›® README**: https://github.com/fsxbmb/Ai-Writer
- **Ollama æ–‡æ¡£**: https://ollama.com/docs
- **MinerU æ–‡æ¡£**: https://github.com/opendatalab/MinerU
- **Milvus æ–‡æ¡£**: https://milvus.io/docs

---

## âš¡ å¿«é€Ÿå‚è€ƒ

### ç«¯å£è¯´æ˜
- **5173**: å‰ç«¯å¼€å‘æœåŠ¡å™¨
- **8000**: åç«¯ API æœåŠ¡å™¨
- **11434**: Ollama API æœåŠ¡
- **19530**: Milvus å‘é‡æ•°æ®åº“
- **9091**: Milvus ç®¡ç†ç•Œé¢
- **9001**: MinIO æ§åˆ¶å°

### ç›®å½•ç»“æ„
```
Ai-Writer/
â”œâ”€â”€ backend/         # Python FastAPI åç«¯
â”‚   â”œâ”€â”€ app/        # åº”ç”¨ä»£ç 
â”‚   â”œâ”€â”€ data/       # æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ uploads/    # ä¸Šä¼ æ–‡ä»¶
â”‚   â””â”€â”€ venv/       # è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ frontend/       # Vue 3 å‰ç«¯
â”‚   â””â”€â”€ src/       # æºä»£ç 
â”œâ”€â”€ milvus/        # å‘é‡æ•°æ®åº“é…ç½®
â””â”€â”€ DEPLOYMENT.md  # æœ¬æ–‡ä»¶
```

### å¸¸ç”¨å‘½ä»¤
```bash
# å¯åŠ¨åç«¯
cd backend && python -m app.main

# å¯åŠ¨å‰ç«¯
cd frontend && npm run dev

# å¯åŠ¨ Ollama
ollama serve

# å¯åŠ¨ Milvus
cd milvus && docker compose up -d

# æŸ¥çœ‹æ—¥å¿—
tail -f backend/logs/*.log
```

### ç¯å¢ƒå˜é‡å‚è€ƒ

```env
# åç«¯ .env é…ç½®
DEBUG=True
PORT=8000

# Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b

# Milvus
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

---

## ğŸ“„ è®¸å¯è¯

MIT License
